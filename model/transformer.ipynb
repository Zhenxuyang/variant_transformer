{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#coding=utf-8\n","\n","'''\n","Enhancer Transformer的实现\n","'''\n","\n","from numpy.core.fromnumeric import var\n","import torch\n","from torch.nn.modules.loss import BCELoss\n","from torch.utils.data.dataloader import DataLoader\n","from torch import nn\n","import torch.nn.functional as F\n","import math\n","from torch.utils.data import Dataset, Subset\n","import pandas as pd\n","from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from torch import Tensor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class TransformerEmbedding(nn.Module):\n","    def __init__(self, embedding_num, embedding_dim, pad_idx, device) -> None:\n","        super().__init__()\n","        self.embedding = nn.Embedding(embedding_num, embedding_dim, pad_idx, device=device)\n","\n","    def forward(self, x):\n","        x = self.embedding(x)\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# class PositionalEncoding(nn.Module):\n","#     \"\"\"\n","#     compute sinusoid encoding.\n","#     \"\"\"\n","#     def __init__(self, d_model, max_len, device):\n","#         \"\"\"\n","#         constructor of sinusoid encoding class\n","\n","#         :param d_model: dimension of model\n","#         :param max_len: max sequence length\n","#         :param device: hardware device setting\n","#         \"\"\"\n","#         super(PositionalEncoding, self).__init__()\n","\n","#         # same size with input matrix (for adding with input matrix)\n","#         self.encoding = torch.zeros(max_len, d_model, device=device)\n","#         self.encoding.requires_grad = False  # we don't need to compute gradient\n","\n","#         pos = torch.arange(0, max_len, device=device)\n","#         pos = pos.float().unsqueeze(dim=1)\n","#         # 1D => 2D unsqueeze to represent word's position\n","\n","#         _2i = torch.arange(0, d_model, step=2, device=device).float()\n","#         # 'i' means index of d_model (e.g. embedding size = 50, 'i' = [0,50])\n","#         # \"step=2\" means 'i' multiplied with two (same with 2 * i)\n","#         self.encoding[:, 0::2] = torch.sin(pos / (10000 ** (_2i / d_model)))\n","#         if d_model % 2 == 1:\n","#             _2i = _2i[:-1]\n","#         self.encoding[:, 1::2] = torch.cos(pos / (10000 ** (_2i / d_model)))\n","#         # compute positional encoding to consider positional information of words\n","\n","#     def forward(self, x):\n","#         # self.encoding\n","#         # [max_len = 512, d_model = 512]\n","\n","#         batch_size, seq_len, d_model= x.size()\n","#         # [batch_size = 128, seq_len = 30]\n","\n","#         return x + self.encoding[:seq_len, :]\n","#         # [seq_len = 30, d_model = 512]\n","#         # it will add with tok_emb : [128, 30, 512]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 以突变位点为中心实现位置编码\n","\n","class PositionalEncoding(nn.Module):\n","\n","    def __init__(self, d_model, seq_len, device) -> None:\n","        super().__init__()\n","        self.encoding = torch.zeros(seq_len, d_model, device=device)\n","        self.encoding.requires_grad = False\n","    \n","        assert seq_len%2==1\n","        pos = torch.arange(0, seq_len, device=device)\n","        half = int((seq_len-1)/2)\n","        pos[:half] = torch.arange(half, 0, step=-1)\n","        pos[half+1:] = torch.arange(1, half+1)\n","        pos[half] = 0\n","        pos = pos.float().unsqueeze(dim=1)\n","\n","        _2i = torch.arange(-0, d_model, step=2, device=device).float()\n","        self.encoding[:, 0::2] = torch.sin(pos/(10**(_2i/d_model)))\n","        if d_model%2 == 1:\n","            _2i = _2i[:-1]\n","        self.encoding[:, 1::2] = torch.cos(pos/(10**(_2i/d_model)))\n","    \n","    def getEncoding(self):\n","        return self.encoding\n","    \n","    def forward(self, x):\n","        batch_size, seq_len, d_model = x.size()\n","        return x + self.encoding[:seq_len, :]\n","\n","# p = PositionalEncoding(10, 501, 'cpu')\n","# fig = plt.figure(figsize=(20, 20))\n","# ax = fig.add_subplot(111)\n","# encoding = p.getEncoding()\n","# print(encoding)\n","# im=ax.imshow(encoding,cmap='plasma_r')\n","# plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class MultiHeadAttention(nn.Module):\n","\n","    def __init__(self, d_model, n_head):\n","        super(MultiHeadAttention, self).__init__()\n","        self.n_head = n_head\n","        self.attention = ScaleDotProductAttention()\n","        self.w_q = nn.Linear(d_model, d_model)\n","        self.w_k = nn.Linear(d_model, d_model)\n","        self.w_v = nn.Linear(d_model, d_model)\n","        self.w_concat = nn.Linear(d_model, d_model)\n","\n","    def forward(self, q, k, v, mask=None):\n","        # 1. dot product with weight matrices\n","        q, k, v = self.w_q(q), self.w_k(k), self.w_v(v)\n","\n","        # 2. split tensor by number of heads\n","        q, k, v = self.split(q), self.split(k), self.split(v)\n","\n","        # 3. do scale dot product to compute similarity\n","        out, attention = self.attention(q, k, v, mask=mask)\n","        \n","        # 4. concat and pass to linear layer\n","        out = self.concat(out)\n","        out = self.w_concat(out)\n","\n","        # 5. visualize attention map\n","        # TODO : we should implement visualization\n","\n","        return out\n","\n","    def split(self, tensor):\n","        \"\"\"\n","        split tensor by number of head\n","\n","        :param tensor: [batch_size, length, d_model]\n","        :return: [batch_size, head, length, d_tensor]\n","        \"\"\"\n","        batch_size, length, d_model = tensor.size()\n","\n","        d_tensor = d_model // self.n_head\n","        tensor = tensor.view(batch_size, self.n_head, length, d_tensor)\n","        # it is similar with group convolution (split by number of heads)\n","\n","        return tensor\n","\n","    def concat(self, tensor):\n","        \"\"\"\n","        inverse function of self.split(tensor : torch.Tensor)\n","\n","        :param tensor: [batch_size, head, length, d_tensor]\n","        :return: [batch_size, length, d_model]\n","        \"\"\"\n","        batch_size, head, length, d_tensor = tensor.size()\n","        d_model = head * d_tensor\n","\n","        tensor = tensor.view(batch_size, length, d_model)\n","        return tensor\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class ScaleDotProductAttention(nn.Module):\n","    \"\"\"\n","    compute scale dot product attention\n","\n","    Query : given sentence that we focused on (decoder)\n","    Key : every sentence to check relationship with Qeury(encoder)\n","    Value : every sentence same with Key (encoder)\n","    \"\"\"\n","\n","    def __init__(self):\n","        super(ScaleDotProductAttention, self).__init__()\n","        self.softmax = nn.Softmax(-1)\n","\n","    def forward(self, q, k, v, mask=None, e=1e-12):\n","        # input is 4 dimension tensor\n","        # [batch_size, head, length, d_tensor]\n","        batch_size, head, length, d_tensor = k.size()\n","\n","        # 1. dot product Query with Key^T to compute similarity\n","        # k_t = k.view(batch_size, head, d_tensor, length)  # transpose\n","        k_t = k.permute(0, 1, 3, 2)\n","        score = (q @ k_t) / math.sqrt(d_tensor)  # scaled dot product\n","\n","        # 2. apply masking (opt)\n","        if mask is not None:\n","            score = score.masked_fill(mask == 0, -e)\n","\n","        # 3. pass them softmax to make [0, 1] range\n","        score = self.softmax(score)\n","\n","        # 4. multiply with Value\n","        v = score @ v\n","\n","        return v, score\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Attention(nn.Module):\n","\n","    def __init__(self, seq_len, embedding_dim, device=None) -> None:\n","        super().__init__()\n","        self.seq_len = seq_len\n","        self.device = device\n","        self.embedding_dim = embedding_dim\n","        self.w_q = nn.Linear(embedding_dim, embedding_dim)\n","        self.w_k = nn.Linear(embedding_dim, embedding_dim)\n","        self.w_v = nn.Linear(embedding_dim, embedding_dim)\n","        self.layer_norm = nn.LayerNorm([seq_len, 1])\n","        # self.softmax = nn.Softmax(-1)\n","\n","    def forward(self, x):\n","        batch_size, seq_len, d_model = x.size()\n","        q = self.w_q(x)\n","        v = self.w_v(x)\n","        # k = x[:, (seq_len+1)/2, :]\n","        k = torch.index_select(x, 1, torch.tensor(seq_len//2).to(self.device))\n","        k_t = k.permute(0, 2, 1)\n","        # 计算注意力\n","        score = (q @ k_t) / math.sqrt(d_model)\n","        # v = score@v\n","        score = self.layer_norm(score)\n","        return score"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Classifier_with_simple_attention(nn.Module):\n","\n","    def __init__(self, input_dim, output_dim) -> None:\n","        super().__init__()\n","        self.linear1 = nn.Sequential(\n","            nn.Linear(input_dim, 64),\n","            nn.ReLU()\n","        )\n","        self.linear2 = nn.Sequential(\n","            nn.Linear(64, output_dim),\n","            nn.ReLU()\n","        )\n","        self.sigmoid = nn.Sigmoid()\n","    \n","    def forward(self, x):\n","        x = self.linear1(x)\n","        x = self.linear2(x)\n","        x = self.sigmoid(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class VTC_with_simple_attention(nn.Module):\n","\n","    def __init__(self, seq_len, embedding_dim, input_dim, output_dim, device=None) -> None:\n","        super().__init__()\n","        self.att_layer = Attention(seq_len, embedding_dim, device)\n","        self.classifier = Classifier_with_simple_attention(input_dim, output_dim)\n","        self.device = device\n","    \n","    def embedding(self, x, y, device):\n","        batch_size, length = x.size()\n","        x_ = torch.zeros(batch_size, length, 5).to(device)\n","        x = x.view(batch_size, -1, 1)\n","        x_.scatter_(2, x, 1)\n","        y_ = torch.zeros(batch_size, length, 5).to(device)\n","        y = y.view(batch_size, -1, 1)\n","        y_.scatter_(2, y, 1)\n","        return torch.cat((x_, y_), 2)\n","    \n","    def forward(self, x, y):\n","        x = self.embedding(x, y, self.device)\n","        x = self.att_layer(x)\n","        batch_size, seq_len, _ = x.size()\n","        x = x.view(batch_size, -1)\n","        x = self.classifier(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dummy_input1 = torch.randn(10, 2001, 10)\n","att = Attention(2001, 10)\n","output = att(dummy_input1)\n","# dummy_input2 = torch.randn(10, 1001, 5)\n","# att = VTC_with_simple_attention(1001, 10, 1001, 1)\n","# output = att(dummy_input1, dummy_input2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class LayerNorm(nn.Module):\n","    def __init__(self, d_model, eps=1e-12):\n","        super(LayerNorm, self).__init__()\n","        self.gamma = nn.Parameter(torch.ones(d_model))\n","        self.beta = nn.Parameter(torch.zeros(d_model))\n","        self.eps = eps\n","\n","    def forward(self, x):\n","        mean = x.mean(-1, keepdim=True)\n","        std = x.std(-1, keepdim=True)\n","        # '-1' means last dimension. \n","\n","        out = (x - mean) / (std + self.eps)\n","        out = self.gamma * out + self.beta\n","        return out\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class PositionwiseFeedForward(nn.Module):\n","\n","    def __init__(self, d_model, hidden, drop_prob=0.1):\n","        super(PositionwiseFeedForward, self).__init__()\n","        self.linear1 = nn.Linear(d_model, hidden)\n","        self.linear2 = nn.Linear(hidden, d_model)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(p=drop_prob)\n","\n","    def forward(self, x):\n","        x = self.linear1(x)\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.linear2(x)\n","        return x\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class EncoderLayer(nn.Module):\n","\n","    def __init__(self, d_model, ffn_hidden, n_head, drop_prob):\n","        super(EncoderLayer, self).__init__()\n","        self.attention = MultiHeadAttention(d_model=d_model, n_head=n_head)\n","        self.norm1 = LayerNorm(d_model=d_model)\n","        self.dropout1 = nn.Dropout(p=drop_prob)\n","\n","        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n","        self.norm2 = LayerNorm(d_model=d_model)\n","        self.dropout2 = nn.Dropout(p=drop_prob)\n","\n","    def forward(self, x, src_mask):\n","        # 1. compute self attention\n","        _x = x\n","        x = self.attention(q=x, k=x, v=x, mask=src_mask)\n","        \n","        # 2. add and norm\n","        x = self.norm1(x + _x)\n","        x = self.dropout1(x)\n","        \n","        # 3. positionwise feed forward network\n","        _x = x\n","        x = self.ffn(x)\n","      \n","        # 4. add and norm\n","        x = self.norm2(x + _x)\n","        x = self.dropout2(x)\n","        return x\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Encoder(nn.Module):\n","\n","    def __init__(self, d_model, ffn_hidden, n_head, n_layers, drop_prob, device):\n","        super().__init__()\n","        self.layers = nn.ModuleList([EncoderLayer(d_model=d_model,\n","                                                  ffn_hidden=ffn_hidden,\n","                                                  n_head=n_head,\n","                                                  drop_prob=drop_prob)\n","                                     for _ in range(n_layers)])\n","\n","    def forward(self, x, src_mask):\n","        for layer in self.layers:\n","            x = layer(x, src_mask)\n","\n","        return x\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Conv(nn.Module):\n","    \n","    def __init__(self, seq_len, embedding_dim, output_dim, kernel_size) -> None:\n","        super().__init__()\n","        self.conv = nn.Conv1d(embedding_dim, output_dim, kernel_size=kernel_size)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout()\n","        self.max_pool = nn.MaxPool1d(3, 2)\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.max_pool(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\"\"\"\n","use CNN to compress lone sequences\n","\"\"\"\n","\n","class Convs(nn.Module):\n","    \n","    def __init__(self, seq_len, embedding_dim, output_dim, n_layers=4, kernel_size=5) -> None:\n","        super().__init__()\n","        self.layers = nn.ModuleList([Conv(seq_len, embedding_dim, output_dim, kernel_size)\n","            for _ in range(n_layers)\n","        ])\n","    \n","    def forward(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x\n","\n","'''\n","50*5*120 50*5*120\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# dummy_input = torch.rand(50, 2001, 5)\n","# dummy_input = dummy_input.permute(0, 2, 1)\n","# convs1 = Convs(2001, 5, 5)\n","# output = convs1(dummy_input)\n","# pass"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# class ClassificationLayer(nn.Module):\n","#     def __init__(self, embedding_dim, seq_len, output_dim) -> None:\n","#         super().__init__()\n","#         self.linear1 = nn.Linear(embedding_dim, 1)\n","#         self.linear2 = nn.Linear(seq_len, output_dim)\n","#         self.leaky_relu = nn.LeakyReLU()\n","#         self.sigmoid = nn.Sigmoid()\n","\n","#     def forward(self, x):\n","#         batch_size, _, _ = x.size() \n","#         x = self.linear1(x)\n","#         x = self.leaky_relu(x)\n","#         x = x.view(batch_size, -1)\n","#         x = self.linear2(x)\n","#         x = self.sigmoid(x)\n","#         return x\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class ClassificationLayer(nn.Module):\n","    def __init__(self,  embedding_dim, seq_len, output_dim) -> None:\n","        super().__init__()\n","        # self.conv1 = nn.Conv1d(10, 2, kernel_size=10)\n","        # self.relu1 = nn.ReLU()\n","        # self.conv2 = nn.Conv1d(2, 10, kernel_size=5)\n","        # self.relu2 = nn.ReLU()\n","        # self.dropout = nn.Dropout()\n","        self.conv1 = nn.Sequential(\n","            nn.Conv1d(in_channels=10, out_channels=20, kernel_size=3),\n","            nn.ReLU(),\n","            nn.MaxPool1d(3, 2)\n","        )\n","        self.conv2 = nn.Sequential(\n","            nn.Conv1d(in_channels=20, out_channels=40, kernel_size=3),\n","            nn.ReLU(),\n","            nn.MaxPool1d(3,2)\n","        )\n","        \"\"\"\n","        1001 9920\n","        201 1920\n","        \"\"\"\n","        # 1001 9920\n","        self.linear1 = nn.Linear(1080, 512)\n","        self.linear2 = nn.Linear(512, 256)\n","        self.linear3 = nn.Linear(256, 1)\n","\n","        # self.dense = nn.Sequential(\n","        #     nn.Linear(1080, 512),\n","        #     nn.ReLU(),\n","        #     nn.Dropout(),\n","        #     nn.Linear(512, 256),\n","        #     nn.ReLU(),\n","        #     nn.Dropout(),\n","        #     nn.Linear(256, 1)\n","        # )\n","        self.sigmoid = nn.Sigmoid()\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout()\n","        self.layernorm1 = nn.LayerNorm(512)\n","        self.layernorm2 = nn.LayerNorm(256)\n","        # self.linear1 = nn.Linear(, 50)\n","    \n","    def forward(self, x):\n","        # print(\"CNN classifier\")\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = x.view(x.size(0), -1)\n","        # x = self.dense(x)\n","        x = self.linear1(x)\n","        x = self.dropout(self.relu(x))\n","        x = self.layernorm1(x)\n","        x = self.linear2(x)\n","        x = self.dropout(self.relu(x))\n","        x = self.layernorm2(x)\n","        x = self.linear3(x)\n","        # x = self.dropout(self.relu(x))\n","        x = self.sigmoid(x)\n","        return x\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# input = torch.randn([50, 10, 201])\n","# classifier = ClassificationLayer(10, 201, 1)\n","# out = classifier(input)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class VariantPathogenicityClassifier(nn.Module):\n","    def __init__(self, params, device) -> None:\n","        super().__init__()\n","        self.pad_idx = params.pad_idx\n","        self.device = device\n","        self.positionalEncoding = PositionalEncoding(\n","            d_model=params.embedding_dim,\n","            seq_len=params.seq_len,\n","            device=device\n","        )\n","        self.convs = Convs(\n","            seq_len=params.seq_len,\n","            embedding_dim=params.embedding_dim,\n","            output_dim=params.pre_cnn_output_dim,\n","            n_layers=params.pre_cnn_n_layers)\n","        self.encoder = Encoder(\n","            d_model=params.pre_cnn_output_dim,\n","            ffn_hidden=params.hidden_dim,\n","            n_head=params.att_head_num,\n","            n_layers=params.n_layers,\n","            drop_prob=params.trans_drop_prob,\n","            device=device\n","        )\n","        self.classifier = ClassificationLayer(params.pre_cnn_output_dim, params.pre_cnn_output_seq_len, params.output_dim)\n","    \n","    def make_pad_mask(self, q, k, src_padding_idx):\n","        len_q, len_k = q.size(1), k.size(1)\n","\n","        # batch_size x 1 x 1 x len_k\n","        k = k.ne(src_padding_idx).unsqueeze(1).unsqueeze(2)\n","        # batch_size x 1 x len_q x len_k\n","        k = k.repeat(1, 1, len_q, 1)\n","\n","        # batch_size x 1 x len_q x 1\n","        q = q.ne(src_padding_idx).unsqueeze(1).unsqueeze(3)\n","        # batch_size x 1 x len_q x len_k\n","        q = q.repeat(1, 1, 1, len_k)\n","\n","        mask = k & q\n","        return mask\n","    \n","    def embedding(self, x, y, device):\n","        batch_size, length = x.size()\n","        x_ = torch.zeros(batch_size, length, 5).to(device)\n","        x = x.view(batch_size, -1, 1)\n","        x_.scatter_(2, x, 1)\n","        y_ = torch.zeros(batch_size, length, 5).to(device)\n","        y = y.view(batch_size, -1, 1)\n","        y_.scatter_(2, y, 1)\n","        return torch.cat((x_, y_), 2)\n","          \n","    def forward(self, x, y):\n","        # src_mask = self.make_pad_mask(x, x, self.pad_idx)\n","        src_mask = None\n","        x = self.embedding(x, y, self.device)\n","        x = self.positionalEncoding(x)\n","        x = x.permute(0, 2, 1)\n","        x = self.convs(x)\n","        x = x.permute(0, 2, 1)\n","        x = self.encoder(x, src_mask)\n","        x = x.permute(0, 2, 1)\n","        x = self.classifier(x)\n","        return x\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class MLPClassifier(nn.Module):\n","\n","    def __init__(self, seq_len, embedding_dim, output_dim, device) -> None:\n","        super().__init__()\n","        self.device = device\n","        self.linear1 = nn.Linear(embedding_dim, 1)\n","        self.relu = nn.ReLU()\n","        self.linear2 = nn.Linear(seq_len, output_dim)\n","        self.sigmoid = nn.Sigmoid()\n","    \n","    def embedding(self, x, y, device):\n","        batch_size, length = x.size()\n","        x_ = torch.zeros(batch_size, length, 5).to(device)\n","        x = x.view(batch_size, -1, 1)\n","        x_.scatter_(2, x, 1)\n","        y_ = torch.zeros(batch_size, length, 5).to(device)\n","        y = y.view(batch_size, -1, 1)\n","        y_.scatter_(2, y, 1)\n","        return torch.cat((x_, y_), 2)\n","\n","    def forward(self, x, y):\n","        x = self.embedding(x, y, self.device)\n","        x = self.linear1(x)\n","        x = self.relu(x)\n","        batch_size, _, _ = x.size() \n","        x = x.view(batch_size, -1)\n","        x = self.linear2(x)\n","        x = self.sigmoid(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 自定义加权loss\n","class WeightedBCELoss(nn.Module):\n","\n","    def __init__(self, pos_weight: float=1.0,  reduction: str='mean') -> None:\n","        super().__init__()\n","        self.pos_weight = pos_weight\n","        self.reduction = reduction\n","    \n","    def forward(self, input:Tensor, target:Tensor) -> Tensor:\n","        loss = F.binary_cross_entropy(input, target, reduction='none')\n","        weights = torch.full_like(target, 1-self.pos_weight)\n","        weights[target==1] = self.pos_weight\n","        loss = loss * weights\n","        if self.reduction == 'mean':\n","            loss = torch.mean(loss)\n","        elif self.reduction == 'sum':\n","            loss = torch.sum(loss)\n","\n","        return loss\n","        \n","        "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# t = torch.randn(50, 1)\n","# input = torch.rand_like(t)\n","# target = torch.randint_like(t, 2)\n","# print(input)\n","# print(target)\n","# loss_func = WeightedBCELoss()\n","# pos_weight = 0.75\n","# loss = loss_func(input, target, pos_weight)\n","# print(loss)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import imp\n","params = imp.load_source('params', 'params.py')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class VariantDataset(Dataset):\n","    def __init__(self, file_path) -> None:\n","        self.raw_data = pd.read_csv(file_path)\n","        self.encode_seq()\n","\n","    def __len__(self):\n","        return self.raw_data.shape[0]\n","\n","    def __getitem__(self, index):\n","        variant = self.raw_data.iloc[index]\n","        ref = torch.tensor(variant['encoded_ref'])\n","        alt = torch.tensor(variant['encoded_alt'])\n","        label = torch.tensor(variant['label'])\n","        return [ref, alt, label]\n","    \n","    def encode_seq(self):\n","        # 编码\n","        dict_ = {\n","            'A': 1,\n","            'T': 2,\n","            'C': 3,\n","            'G': 4,\n","            'N': 0\n","        }\n","        self.raw_data['encoded_ref'] = self.raw_data['seq_1000_ref'].apply(lambda x: list(map(lambda i: dict_[i], list(x))))\n","        self.raw_data['encoded_alt'] = self.raw_data['seq_1000_alt'].apply(lambda x: list(map(lambda i: dict_[i], list(x))))\n","                "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trainset = VariantDataset('../data/train.csv')\n","validset = VariantDataset('../data/valid.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trainLoader = DataLoader(trainset, batch_size=params.batch_size, shuffle=True)\n","validLoader = DataLoader(validset, batch_size=params.batch_size, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# model = VariantPathogenicityClassifier(params, device)\n","\n","# model = MLPClassifier(\n","#     seq_len=seq_len,\n","#     embedding_dim = embedding_dim,\n","#     output_dim=output_dim,\n","#     device=device\n","# )\n","\n","model = VTC_with_simple_attention(params.seq_len, params.embedding_dim, params.seq_len, params.output_dim, device)\n","model=model.to(device)\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=params.learning_rate)\n","\n","# loss_func = BCELoss()\n","loss_func = WeightedBCELoss(pos_weight=0.75)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tensorboardX import SummaryWriter\n","writer = SummaryWriter()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train(model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    loss_sum = 0\n","    for batch_idx, (x, y, target) in enumerate(train_loader):\n","        x, y, target = x.to(device), y.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(x, y)\n","        target = torch.unsqueeze(target, 1)\n","        # output=output.to(torch.float32)\n","        target=target.to(torch.float32)\n","        loss = loss_func(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        loss_sum += loss.item()\n","        if batch_idx % params.log_interval == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(x), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))\n","    loss_avg = loss_sum/(batch_idx+1)\n","    writer.add_scalar('Train_loss', loss_avg, epoch)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def metrics(confusion_matrix):\n","    epsilon = 1e-7\n","    sum = np.sum(confusion_matrix)\n","    tn, fp, fn, tp = confusion_matrix.ravel()\n","    accuracy = (tn + tp)/sum\n","    precision = tp / (tp + fp + epsilon)\n","    recall = tp / (tp + fn + epsilon)\n","    f1 = 2*precision*recall/(precision+recall+epsilon)\n","    return accuracy, precision, recall, f1\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def valid(model, device, validloader, epoch):\n","    model.eval()\n","    test_loss = 0\n","    thresholds = [0.2, 0.25, 0.3, 0.4, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.6, 0.7]\n","    threshold_num = len(thresholds)\n","    correct = [0 for i in range(threshold_num)]\n","    y_pred_thres = [[] for i in range(threshold_num)]\n","    confusion_matrixs = [np.array([[0, 0], [0, 0]]) for i in range(threshold_num)]\n","    y_true =[]\n","    with torch.no_grad():\n","        for x, y, target in validloader:\n","            x, y, target = x.to(device), y.to(device), target.to(device)\n","            output = model(x, y)\n","            target = torch.unsqueeze(target, 1)\n","            target = target.to(torch.float32)\n","            test_loss += F.binary_cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n","            target = target.reshape(1, -1)\n","            # y_true.extend(target[0])\n","            for i in range(len(thresholds)):\n","                pred = (output > thresholds[i]).to(torch.float32)\n","                pred = pred.reshape(1, -1)\n","                # y_pred_thres[i].extend(pred[0])\n","                matched = pred.eq(target).sum().item()\n","                # correct[i] = correct[i] + matched\n","                confusion_matrixs[i] = confusion_matrixs[i] + confusion_matrix(target[0].cpu(), pred[0].cpu())\n","                \n","    test_loss /= len(validLoader.dataset)\n","    writer.add_scalar('Test_loss', test_loss, epoch)\n","    # acc = []\n","    # for c in correct:\n","    #     acc.append(c / (len(validLoader.dataset)))\n","    # writer.add_scalar('Validation_accuracy', acc[2], epoch)\n","    accs = {}\n","    precs = {}\n","    recalls = {}\n","    f1s = {}\n","    for i in range(threshold_num):\n","        accuracy, precision, recall, f1= metrics(confusion_matrixs[i])\n","        print(thresholds[i], accuracy, precision, recall, f1)\n","        accs[str(thresholds[i])] = accuracy\n","        precs[str(thresholds[i])] = precision\n","        recalls[str(thresholds[i])] = recall\n","        f1s[str(thresholds[i])] = f1\n","    writer.add_scalars('Evaluation_performance_acc', accs, global_step=epoch)\n","    writer.add_scalars('Evaluation_performance_precision', precs, global_step=epoch)\n","    writer.add_scalars('Evaluation_performance_recall', recalls, global_step=epoch)\n","    writer.add_scalars('Evaluation_performance_f1', f1s, global_step=epoch)\n","\n","    print('\\nTest set: Average loss: {:.4f}'.format(test_loss))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for i in range(params.epoch):\n","    print(i)\n","    train(model, device, trainLoader, optimizer, i)\n","    valid(model, device, validLoader, i)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["valid(model, device, validLoader, 1)"]}],"metadata":{"interpreter":{"hash":"796fac6b8cc66e26d7d5167379612d61b69e4c93c285e3908b5ef16019a4c00d"},"kernelspec":{"display_name":"Python 3.7.9 64-bit ('variant_transformer': virtualenv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
