{"cells":[{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["#coding=utf-8\n","\n","'''\n","Enhancer Transformer的实现\n","'''\n","\n","from numpy.core.fromnumeric import var\n","import torch\n","from torch.nn.modules.loss import BCELoss\n","from torch.utils.data.dataloader import DataLoader\n","from torch import nn\n","import torch.nn.functional as F\n","import math\n","from torch.utils.data import Dataset, Subset\n","import pandas as pd\n","from sklearn.metrics import confusion_matrix\n","\n"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["class VariantDataset(Dataset):\n","    def __init__(self, file_path) -> None:\n","        self.raw_data = pd.read_csv(file_path)\n","        self.encode_seq()\n","\n","    def __len__(self):\n","        return self.raw_data.shape[0]\n","\n","    def __getitem__(self, index):\n","        variant = self.raw_data.iloc[index]\n","        ref = torch.tensor(variant['encoded_ref'])\n","        alt = torch.tensor(variant['encoded_alt'])\n","        label = torch.tensor(variant['label'])\n","        return [ref, alt, label]\n","    \n","    def encode_seq(self):\n","        # 编码\n","        dict_ = {\n","            'A': 1,\n","            'T': 2,\n","            'C': 3,\n","            'G': 4,\n","            'N': 0\n","        }\n","        self.raw_data['encoded_ref'] = self.raw_data['seq_101_ref'].apply(lambda x: list(map(lambda i: dict_[i], list(x))))\n","        self.raw_data['encoded_alt'] = self.raw_data['seq_101_alt'].apply(lambda x: list(map(lambda i: dict_[i], list(x))))\n","                \n","\n"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["class TransformerEmbedding(nn.Module):\n","    def __init__(self, embedding_num, embedding_dim, pad_idx, device) -> None:\n","        super().__init__()\n","        self.embedding = nn.Embedding(embedding_num, embedding_dim, pad_idx, device=device)\n","\n","    def forward(self, x):\n","        x = self.embedding(x)\n","        return x\n"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","    \"\"\"\n","    compute sinusoid encoding.\n","    \"\"\"\n","    def __init__(self, d_model, max_len, device):\n","        \"\"\"\n","        constructor of sinusoid encoding class\n","\n","        :param d_model: dimension of model\n","        :param max_len: max sequence length\n","        :param device: hardware device setting\n","        \"\"\"\n","        super(PositionalEncoding, self).__init__()\n","\n","        # same size with input matrix (for adding with input matrix)\n","        self.encoding = torch.zeros(max_len, d_model, device=device)\n","        self.encoding.requires_grad = False  # we don't need to compute gradient\n","\n","        pos = torch.arange(0, max_len, device=device)\n","        pos = pos.float().unsqueeze(dim=1)\n","        # 1D => 2D unsqueeze to represent word's position\n","\n","        _2i = torch.arange(0, d_model, step=2, device=device).float()\n","        # 'i' means index of d_model (e.g. embedding size = 50, 'i' = [0,50])\n","        # \"step=2\" means 'i' multiplied with two (same with 2 * i)\n","        self.encoding[:, 0::2] = torch.sin(pos / (10000 ** (_2i / d_model)))\n","        if d_model % 2 == 1:\n","            _2i = _2i[:-1]\n","        self.encoding[:, 1::2] = torch.cos(pos / (10000 ** (_2i / d_model)))\n","        # compute positional encoding to consider positional information of words\n","\n","    def forward(self, x):\n","        # self.encoding\n","        # [max_len = 512, d_model = 512]\n","\n","        batch_size, seq_len, d_model= x.size()\n","        # [batch_size = 128, seq_len = 30]\n","\n","        return x + self.encoding[:seq_len, :]\n","        # [seq_len = 30, d_model = 512]\n","        # it will add with tok_emb : [128, 30, 512]\n","\n"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["class MultiHeadAttention(nn.Module):\n","\n","    def __init__(self, d_model, n_head):\n","        super(MultiHeadAttention, self).__init__()\n","        self.n_head = n_head\n","        self.attention = ScaleDotProductAttention()\n","        self.w_q = nn.Linear(d_model, d_model)\n","        self.w_k = nn.Linear(d_model, d_model)\n","        self.w_v = nn.Linear(d_model, d_model)\n","        self.w_concat = nn.Linear(d_model, d_model)\n","\n","    def forward(self, q, k, v, mask=None):\n","        # 1. dot product with weight matrices\n","        q, k, v = self.w_q(q), self.w_k(k), self.w_v(v)\n","\n","        # 2. split tensor by number of heads\n","        q, k, v = self.split(q), self.split(k), self.split(v)\n","\n","        # 3. do scale dot product to compute similarity\n","        out, attention = self.attention(q, k, v, mask=mask)\n","        \n","        # 4. concat and pass to linear layer\n","        out = self.concat(out)\n","        out = self.w_concat(out)\n","\n","        # 5. visualize attention map\n","        # TODO : we should implement visualization\n","\n","        return out\n","\n","    def split(self, tensor):\n","        \"\"\"\n","        split tensor by number of head\n","\n","        :param tensor: [batch_size, length, d_model]\n","        :return: [batch_size, head, length, d_tensor]\n","        \"\"\"\n","        batch_size, length, d_model = tensor.size()\n","\n","        d_tensor = d_model // self.n_head\n","        tensor = tensor.view(batch_size, self.n_head, length, d_tensor)\n","        # it is similar with group convolution (split by number of heads)\n","\n","        return tensor\n","\n","    def concat(self, tensor):\n","        \"\"\"\n","        inverse function of self.split(tensor : torch.Tensor)\n","\n","        :param tensor: [batch_size, head, length, d_tensor]\n","        :return: [batch_size, length, d_model]\n","        \"\"\"\n","        batch_size, head, length, d_tensor = tensor.size()\n","        d_model = head * d_tensor\n","\n","        tensor = tensor.view(batch_size, length, d_model)\n","        return tensor\n","\n"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["class ScaleDotProductAttention(nn.Module):\n","    \"\"\"\n","    compute scale dot product attention\n","\n","    Query : given sentence that we focused on (decoder)\n","    Key : every sentence to check relationship with Qeury(encoder)\n","    Value : every sentence same with Key (encoder)\n","    \"\"\"\n","\n","    def __init__(self):\n","        super(ScaleDotProductAttention, self).__init__()\n","        self.softmax = nn.Softmax(-1)\n","\n","    def forward(self, q, k, v, mask=None, e=1e-12):\n","        # input is 4 dimension tensor\n","        # [batch_size, head, length, d_tensor]\n","        batch_size, head, length, d_tensor = k.size()\n","\n","        # 1. dot product Query with Key^T to compute similarity\n","        k_t = k.view(batch_size, head, d_tensor, length)  # transpose\n","        score = (q @ k_t) / math.sqrt(d_tensor)  # scaled dot product\n","\n","        # 2. apply masking (opt)\n","        if mask is not None:\n","            score = score.masked_fill(mask == 0, -e)\n","\n","        # 3. pass them softmax to make [0, 1] range\n","        score = self.softmax(score)\n","\n","        # 4. multiply with Value\n","        v = score @ v\n","\n","        return v, score\n","\n"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["class LayerNorm(nn.Module):\n","    def __init__(self, d_model, eps=1e-12):\n","        super(LayerNorm, self).__init__()\n","        self.gamma = nn.Parameter(torch.ones(d_model))\n","        self.beta = nn.Parameter(torch.zeros(d_model))\n","        self.eps = eps\n","\n","    def forward(self, x):\n","        mean = x.mean(-1, keepdim=True)\n","        std = x.std(-1, keepdim=True)\n","        # '-1' means last dimension. \n","\n","        out = (x - mean) / (std + self.eps)\n","        out = self.gamma * out + self.beta\n","        return out\n","\n"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["class PositionwiseFeedForward(nn.Module):\n","\n","    def __init__(self, d_model, hidden, drop_prob=0.1):\n","        super(PositionwiseFeedForward, self).__init__()\n","        self.linear1 = nn.Linear(d_model, hidden)\n","        self.linear2 = nn.Linear(hidden, d_model)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(p=drop_prob)\n","\n","    def forward(self, x):\n","        x = self.linear1(x)\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.linear2(x)\n","        return x\n","\n"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["class EncoderLayer(nn.Module):\n","\n","    def __init__(self, d_model, ffn_hidden, n_head, drop_prob):\n","        super(EncoderLayer, self).__init__()\n","        self.attention = MultiHeadAttention(d_model=d_model, n_head=n_head)\n","        self.norm1 = LayerNorm(d_model=d_model)\n","        self.dropout1 = nn.Dropout(p=drop_prob)\n","\n","        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n","        self.norm2 = LayerNorm(d_model=d_model)\n","        self.dropout2 = nn.Dropout(p=drop_prob)\n","\n","    def forward(self, x, src_mask):\n","        # 1. compute self attention\n","        _x = x\n","        x = self.attention(q=x, k=x, v=x, mask=src_mask)\n","        \n","        # 2. add and norm\n","        x = self.norm1(x + _x)\n","        x = self.dropout1(x)\n","        \n","        # 3. positionwise feed forward network\n","        _x = x\n","        x = self.ffn(x)\n","      \n","        # 4. add and norm\n","        x = self.norm2(x + _x)\n","        x = self.dropout2(x)\n","        return x\n","\n"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["class Encoder(nn.Module):\n","\n","    def __init__(self, d_model, ffn_hidden, n_head, n_layers, drop_prob, device):\n","        super().__init__()\n","\n","        self.layers = nn.ModuleList([EncoderLayer(d_model=d_model,\n","                                                  ffn_hidden=ffn_hidden,\n","                                                  n_head=n_head,\n","                                                  drop_prob=drop_prob)\n","                                     for _ in range(n_layers)])\n","\n","    def forward(self, x, src_mask):\n","        for layer in self.layers:\n","            x = layer(x, src_mask)\n","\n","        return x\n","\n"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["class ClassificationLayer(nn.Module):\n","    def __init__(self, embedding_dim, seq_len, output_dim) -> None:\n","        super().__init__()\n","        self.linear1 = nn.Linear(embedding_dim, 1)\n","        self.linear2 = nn.Linear(seq_len, output_dim)\n","        self.leaky_relu = nn.LeakyReLU()\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        batch_size, _, _ = x.size() \n","        x = self.linear1(x)\n","        x = self.leaky_relu(x)\n","        x = x.view(batch_size, -1)\n","        x = self.linear2(x)\n","        x = self.sigmoid(x)\n","        return x\n","\n"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["class VariantPathogenicityClassifier(nn.Module):\n","    def __init__(self, \n","        pad_idx,\n","        pad_size,\n","        embedding_dim,\n","        att_head_num,\n","        hidden_dim,\n","        device,\n","        n_layers=3,\n","        drop_prob=0.1,\n","        output_dim=20) -> None:\n","        super().__init__()\n","        self.pad_idx = pad_idx\n","        self.device = device\n","        self.positionalEncoding = PositionalEncoding(\n","            d_model=embedding_dim,\n","            max_len=pad_size,\n","            device=device\n","        )\n","        self.encoder = Encoder(\n","            d_model=embedding_dim,\n","            ffn_hidden=hidden_dim,\n","            n_head=att_head_num,\n","            n_layers=n_layers,\n","            drop_prob=drop_prob,\n","            device=device\n","        )\n","        self.classifier = ClassificationLayer(embedding_dim, pad_size, output_dim)\n","    \n","    def make_pad_mask(self, q, k, src_padding_idx):\n","        len_q, len_k = q.size(1), k.size(1)\n","\n","        # batch_size x 1 x 1 x len_k\n","        k = k.ne(src_padding_idx).unsqueeze(1).unsqueeze(2)\n","        # batch_size x 1 x len_q x len_k\n","        k = k.repeat(1, 1, len_q, 1)\n","\n","        # batch_size x 1 x len_q x 1\n","        q = q.ne(src_padding_idx).unsqueeze(1).unsqueeze(3)\n","        # batch_size x 1 x len_q x len_k\n","        q = q.repeat(1, 1, 1, len_k)\n","\n","        mask = k & q\n","        return mask\n","    \n","    def embedding(self, x, y, device):\n","        batch_size, length = x.size()\n","        x_ = torch.zeros(batch_size, length, 5).to(device)\n","        x = x.view(batch_size, -1, 1)\n","        x_.scatter_(2, x, 1)\n","        y_ = torch.zeros(batch_size, length, 5).to(device)\n","        y = y.view(batch_size, -1, 1)\n","        y_.scatter_(2, y, 1)\n","        return torch.cat((x_, y_), 2)\n","          \n","    def forward(self, x, y):\n","        src_mask = self.make_pad_mask(x, x, self.pad_idx)\n","        x = self.embedding(x, y, self.device)\n","        x = self.positionalEncoding(x)\n","        x = self.encoder(x, src_mask)\n","        x = self.classifier(x)\n","        return x\n","\n"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["# 参数\n","\n","\n","# 类别\n","label_dim = 2\n","output_dim = 1\n","\n","# 序列文件路径\n","# file_path = '/kaggle/input/cancerenhancers/cancerEnhancers_filtered.csv'\n","file_path = \"../data/variants_with_seq.csv\"\n","\n","# pad的长度\n","pad_size = 101\n","# pad的填充索引\n","pad_idx = 0\n","\n","# embedding词典大小\n","embedding_num = 5\n","# embedding维度\n","embedding_dim = 10\n","\n","# encoder层数\n","n_layers = 6\n","\n","# feedfoward网络中隐藏层大小\n","hidden_dim = 32\n","# # 注意力的头数\n","att_head_num = 5\n","\n","# 学习率\n","learning_rate = 0.001\n","\n","# batch大小 \n","batch_size = 200\n","\n","# epoch数\n","epoch = 10\n","\n","# 打印间隔\n","log_interval = 100\n","\n"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["trainset = VariantDataset('../data/train.csv')\n","validset = VariantDataset('../data/valid.csv')\n","# trainset = VariantDataset('/kaggle/input/variants-transformer/data/train.csv')\n","# validset = VariantDataset('/kaggle/input/variants-transformer/data/valid.csv')\n","trainLoader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n","validLoader = DataLoader(validset, batch_size=batch_size, shuffle=True)\n"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[],"source":["model = VariantPathogenicityClassifier(\n","    embedding_dim=embedding_dim,\n","    pad_idx=pad_idx,\n","    pad_size=pad_size,\n","    device=device,\n","    output_dim=output_dim,\n","    att_head_num=att_head_num,\n","    hidden_dim=hidden_dim,\n","    n_layers=n_layers\n",")\n","\n","model=model.to(device)\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","loss_func = BCELoss(weight=torch.tensor([3.]))"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["from tensorboardX import SummaryWriter\n","writer = SummaryWriter()"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[],"source":["def train(model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    loss_sum = 0\n","    for batch_idx, (x, y, target) in enumerate(train_loader):\n","        x, y, target = x.to(device), y.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(x, y)\n","        target = torch.unsqueeze(target, 1)\n","        # output=output.to(torch.float32)\n","        target=target.to(torch.float32)\n","        loss = loss_func(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        loss_sum += loss.item()\n","        if batch_idx % log_interval == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(x), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))\n","    loss_avg = loss_sum/(batch_idx+1)\n","    writer.add_scalar('Train_loss', loss_avg, epoch)"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[],"source":["def valid(model, device, validloader, epoch):\n","    model.eval()\n","    test_loss = 0\n","    correct = [0 for i in range(7)]\n","    thresholds = [0.2, 0.3, 0.4, 0.5, 0.5, 0.6, 0.7]\n","    y_pred_thres = [[] for i in range(7)]\n","    confusion_matrixs = [[[0, 0], [0, 0]] for i in range(7)]\n","    y_true =[]\n","    with torch.no_grad():\n","        for x, y, target in validloader:\n","            x, y, target = x.to(device), y.to(device), target.to(device)\n","            output = model(x, y)\n","            target = torch.unsqueeze(target, 1)\n","            target = target.to(torch.float32)\n","            test_loss += F.binary_cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n","            target = target.reshape(1, -1)\n","            y_true.extend(target[0])\n","            for i in range(len(thresholds)):\n","                pred = (output > thresholds[i]).to(torch.float32)\n","                pred = pred.reshape(1, -1)\n","                y_pred_thres[i].extend(pred[0])\n","                matched = pred.eq(target).sum().item()\n","                correct[i] = correct[i] + matched\n","                confusion_matrixs[i] = confusion_matrixs[i] + confusion_matrix(y_true, y_pred_thres[i])\n","                \n","    test_loss /= len(validLoader.dataset)\n","    writer.add_scalar('Train_loss', test_loss, epoch)\n","    acc = []\n","    for c in correct:\n","        acc.append(c / (len(validLoader.dataset)))\n","    writer.add_scalar('Validation_accuracy', acc[], epoch)\n","\n","    print('\\nTest set: Average loss: {:.4f}'.format(test_loss))\n","    for i in  range(len(thresholds)):\n","        print(confusion_matrixs[i])\n","        print('\\nThreshold:{} Accuracy:{:.0f}%\\n'.format(thresholds[i], 100. * acc[i]))\n","\n"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","Train Epoch: 0 [0/145035 (0%)]\tLoss: 2.266032\n","Train Epoch: 0 [20000/145035 (14%)]\tLoss: 1.535961\n","Train Epoch: 0 [40000/145035 (28%)]\tLoss: 1.747093\n","Train Epoch: 0 [60000/145035 (41%)]\tLoss: 1.535497\n","Train Epoch: 0 [80000/145035 (55%)]\tLoss: 1.831079\n","Train Epoch: 0 [100000/145035 (69%)]\tLoss: 1.686337\n","Train Epoch: 0 [120000/145035 (83%)]\tLoss: 1.683992\n","Train Epoch: 0 [140000/145035 (96%)]\tLoss: 1.615155\n","\n","Test set: Average loss: 0.5769\n","[[3156635  116510]\n"," [1037736   36157]]\n","\n","Threshold:0.2 Accuracy:73%\n","\n","[[3273145       0]\n"," [1073893       0]]\n","\n","Threshold:0.3 Accuracy:75%\n","\n","[[3273145       0]\n"," [1073893       0]]\n","\n","Threshold:0.4 Accuracy:75%\n","\n","[[3273145       0]\n"," [1073893       0]]\n","\n","Threshold:0.5 Accuracy:75%\n","\n","[[3273145       0]\n"," [1073893       0]]\n","\n","Threshold:0.5 Accuracy:75%\n","\n","[[3273145       0]\n"," [1073893       0]]\n","\n","Threshold:0.6 Accuracy:75%\n","\n","[[3273145       0]\n"," [1073893       0]]\n","\n","Threshold:0.7 Accuracy:75%\n","\n","1\n","Train Epoch: 1 [0/145035 (0%)]\tLoss: 1.743316\n","Train Epoch: 1 [20000/145035 (14%)]\tLoss: 1.650165\n","Train Epoch: 1 [40000/145035 (28%)]\tLoss: 1.699414\n","Train Epoch: 1 [60000/145035 (41%)]\tLoss: 1.615603\n","Train Epoch: 1 [80000/145035 (55%)]\tLoss: 1.731664\n","Train Epoch: 1 [100000/145035 (69%)]\tLoss: 1.734214\n","Train Epoch: 1 [120000/145035 (83%)]\tLoss: 1.657661\n","Train Epoch: 1 [140000/145035 (96%)]\tLoss: 1.599437\n","\n","Test set: Average loss: 0.5852\n","[[3271568    1122]\n"," [1074114     234]]\n","\n","Threshold:0.2 Accuracy:75%\n","\n","[[3272690       0]\n"," [1074348       0]]\n","\n","Threshold:0.3 Accuracy:75%\n","\n","[[3272690       0]\n"," [1074348       0]]\n","\n","Threshold:0.4 Accuracy:75%\n","\n","[[3272690       0]\n"," [1074348       0]]\n","\n","Threshold:0.5 Accuracy:75%\n","\n","[[3272690       0]\n"," [1074348       0]]\n","\n","Threshold:0.5 Accuracy:75%\n","\n","[[3272690       0]\n"," [1074348       0]]\n","\n","Threshold:0.6 Accuracy:75%\n","\n","[[3272690       0]\n"," [1074348       0]]\n","\n","Threshold:0.7 Accuracy:75%\n","\n","2\n","Train Epoch: 2 [0/145035 (0%)]\tLoss: 1.604059\n","Train Epoch: 2 [20000/145035 (14%)]\tLoss: 1.675253\n","Train Epoch: 2 [40000/145035 (28%)]\tLoss: 1.671094\n","Train Epoch: 2 [60000/145035 (41%)]\tLoss: 1.602358\n","Train Epoch: 2 [80000/145035 (55%)]\tLoss: 1.803933\n","Train Epoch: 2 [100000/145035 (69%)]\tLoss: 1.845647\n","Train Epoch: 2 [120000/145035 (83%)]\tLoss: 1.707737\n","Train Epoch: 2 [140000/145035 (96%)]\tLoss: 1.495326\n","\n","Test set: Average loss: 0.5761\n","[[3179450   96967]\n"," [1047015   23606]]\n","\n","Threshold:0.2 Accuracy:73%\n","\n","[[3276417       0]\n"," [1070621       0]]\n","\n","Threshold:0.3 Accuracy:75%\n","\n","[[3276417       0]\n"," [1070621       0]]\n","\n","Threshold:0.4 Accuracy:75%\n","\n","[[3276417       0]\n"," [1070621       0]]\n","\n","Threshold:0.5 Accuracy:75%\n","\n","[[3276417       0]\n"," [1070621       0]]\n","\n","Threshold:0.5 Accuracy:75%\n","\n","[[3276417       0]\n"," [1070621       0]]\n","\n","Threshold:0.6 Accuracy:75%\n","\n","[[3276417       0]\n"," [1070621       0]]\n","\n","Threshold:0.7 Accuracy:75%\n","\n","3\n","Train Epoch: 3 [0/145035 (0%)]\tLoss: 1.753149\n","Train Epoch: 3 [20000/145035 (14%)]\tLoss: 1.540032\n","Train Epoch: 3 [40000/145035 (28%)]\tLoss: 1.661651\n","Train Epoch: 3 [60000/145035 (41%)]\tLoss: 1.756779\n","Train Epoch: 3 [80000/145035 (55%)]\tLoss: 1.730687\n","Train Epoch: 3 [100000/145035 (69%)]\tLoss: 1.780743\n","Train Epoch: 3 [120000/145035 (83%)]\tLoss: 1.514036\n","Train Epoch: 3 [140000/145035 (96%)]\tLoss: 1.581927\n","\n","Test set: Average loss: 0.5777\n","[[3236956   33090]\n"," [1070288    6704]]\n","\n","Threshold:0.2 Accuracy:75%\n","\n","[[3270046       0]\n"," [1076992       0]]\n","\n","Threshold:0.3 Accuracy:75%\n","\n","[[3270046       0]\n"," [1076992       0]]\n","\n","Threshold:0.4 Accuracy:75%\n","\n","[[3270046       0]\n"," [1076992       0]]\n","\n","Threshold:0.5 Accuracy:75%\n","\n","[[3270046       0]\n"," [1076992       0]]\n","\n","Threshold:0.5 Accuracy:75%\n","\n","[[3270046       0]\n"," [1076992       0]]\n","\n","Threshold:0.6 Accuracy:75%\n","\n","[[3270046       0]\n"," [1076992       0]]\n","\n","Threshold:0.7 Accuracy:75%\n","\n","4\n","Train Epoch: 4 [0/145035 (0%)]\tLoss: 1.752358\n","Train Epoch: 4 [20000/145035 (14%)]\tLoss: 1.738793\n","Train Epoch: 4 [40000/145035 (28%)]\tLoss: 1.782254\n","Train Epoch: 4 [60000/145035 (41%)]\tLoss: 1.800055\n","Train Epoch: 4 [80000/145035 (55%)]\tLoss: 1.611751\n","Train Epoch: 4 [100000/145035 (69%)]\tLoss: 1.643253\n","Train Epoch: 4 [120000/145035 (83%)]\tLoss: 1.785065\n","Train Epoch: 4 [140000/145035 (96%)]\tLoss: 1.630005\n","\n","Test set: Average loss: 0.5753\n","[[3162981   99734]\n"," [1063199   21124]]\n","\n","Threshold:0.2 Accuracy:73%\n","\n","[[3262715       0]\n"," [1084323       0]]\n","\n","Threshold:0.3 Accuracy:75%\n","\n","[[3262715       0]\n"," [1084323       0]]\n","\n","Threshold:0.4 Accuracy:75%\n","\n","[[3262715       0]\n"," [1084323       0]]\n","\n","Threshold:0.5 Accuracy:75%\n","\n","[[3262715       0]\n"," [1084323       0]]\n","\n","Threshold:0.5 Accuracy:75%\n","\n","[[3262715       0]\n"," [1084323       0]]\n","\n","Threshold:0.6 Accuracy:75%\n","\n","[[3262715       0]\n"," [1084323       0]]\n","\n","Threshold:0.7 Accuracy:75%\n","\n","5\n","Train Epoch: 5 [0/145035 (0%)]\tLoss: 1.664469\n","Train Epoch: 5 [20000/145035 (14%)]\tLoss: 1.770021\n","Train Epoch: 5 [40000/145035 (28%)]\tLoss: 1.810014\n","Train Epoch: 5 [60000/145035 (41%)]\tLoss: 1.653831\n","Train Epoch: 5 [80000/145035 (55%)]\tLoss: 1.818402\n","Train Epoch: 5 [100000/145035 (69%)]\tLoss: 1.632956\n","Train Epoch: 5 [120000/145035 (83%)]\tLoss: 1.580846\n","Train Epoch: 5 [140000/145035 (96%)]\tLoss: 1.621917\n","\n","Test set: Average loss: 0.5779\n","[[3248631   18296]\n"," [1077666    2445]]\n","\n","Threshold:0.2 Accuracy:75%\n","\n","[[3266927       0]\n"," [1080111       0]]\n","\n","Threshold:0.3 Accuracy:75%\n","\n","[[3266927       0]\n"," [1080111       0]]\n","\n","Threshold:0.4 Accuracy:75%\n","\n","[[3266927       0]\n"," [1080111       0]]\n","\n","Threshold:0.5 Accuracy:75%\n","\n","[[3266927       0]\n"," [1080111       0]]\n","\n","Threshold:0.5 Accuracy:75%\n","\n","[[3266927       0]\n"," [1080111       0]]\n","\n","Threshold:0.6 Accuracy:75%\n","\n","[[3266927       0]\n"," [1080111       0]]\n","\n","Threshold:0.7 Accuracy:75%\n","\n","6\n","Train Epoch: 6 [0/145035 (0%)]\tLoss: 1.693530\n","Train Epoch: 6 [20000/145035 (14%)]\tLoss: 1.558637\n","Train Epoch: 6 [40000/145035 (28%)]\tLoss: 1.760121\n","Train Epoch: 6 [60000/145035 (41%)]\tLoss: 1.664043\n","Train Epoch: 6 [80000/145035 (55%)]\tLoss: 1.680786\n","Train Epoch: 6 [100000/145035 (69%)]\tLoss: 1.569327\n","Train Epoch: 6 [120000/145035 (83%)]\tLoss: 1.618117\n","Train Epoch: 6 [140000/145035 (96%)]\tLoss: 1.878400\n","\n","Test set: Average loss: 0.5725\n","[[2896628  371307]\n"," [1001724   77379]]\n","\n","Threshold:0.2 Accuracy:68%\n","\n","[[3267935       0]\n"," [1079103       0]]\n","\n","Threshold:0.3 Accuracy:75%\n","\n","[[3267935       0]\n"," [1079103       0]]\n","\n","Threshold:0.4 Accuracy:75%\n","\n","[[3267935       0]\n"," [1079103       0]]\n","\n","Threshold:0.5 Accuracy:75%\n","\n","[[3267935       0]\n"," [1079103       0]]\n","\n","Threshold:0.5 Accuracy:75%\n","\n","[[3267935       0]\n"," [1079103       0]]\n","\n","Threshold:0.6 Accuracy:75%\n","\n","[[3267935       0]\n"," [1079103       0]]\n","\n","Threshold:0.7 Accuracy:75%\n","\n","7\n","Train Epoch: 7 [0/145035 (0%)]\tLoss: 1.765696\n","Train Epoch: 7 [20000/145035 (14%)]\tLoss: 1.657501\n","Train Epoch: 7 [40000/145035 (28%)]\tLoss: 1.704607\n","Train Epoch: 7 [60000/145035 (41%)]\tLoss: 1.781738\n","Train Epoch: 7 [80000/145035 (55%)]\tLoss: 1.558332\n","Train Epoch: 7 [100000/145035 (69%)]\tLoss: 1.595752\n","Train Epoch: 7 [120000/145035 (83%)]\tLoss: 1.590509\n","Train Epoch: 7 [140000/145035 (96%)]\tLoss: 1.506953\n","\n","Test set: Average loss: 0.5800\n","[[3266513    2484]\n"," [1077767     274]]\n","\n","Threshold:0.2 Accuracy:75%\n","\n","[[3268997       0]\n"," [1078041       0]]\n","\n","Threshold:0.3 Accuracy:75%\n","\n","[[3268997       0]\n"," [1078041       0]]\n","\n","Threshold:0.4 Accuracy:75%\n","\n","[[3268997       0]\n"," [1078041       0]]\n","\n","Threshold:0.5 Accuracy:75%\n","\n","[[3268997       0]\n"," [1078041       0]]\n","\n","Threshold:0.5 Accuracy:75%\n","\n","[[3268997       0]\n"," [1078041       0]]\n","\n","Threshold:0.6 Accuracy:75%\n","\n","[[3268997       0]\n"," [1078041       0]]\n","\n","Threshold:0.7 Accuracy:75%\n","\n","8\n","Train Epoch: 8 [0/145035 (0%)]\tLoss: 1.750658\n","Train Epoch: 8 [20000/145035 (14%)]\tLoss: 1.559095\n","Train Epoch: 8 [40000/145035 (28%)]\tLoss: 1.580142\n","Train Epoch: 8 [60000/145035 (41%)]\tLoss: 1.806665\n","Train Epoch: 8 [80000/145035 (55%)]\tLoss: 1.683047\n","Train Epoch: 8 [100000/145035 (69%)]\tLoss: 1.786267\n","Train Epoch: 8 [120000/145035 (83%)]\tLoss: 1.658561\n","Train Epoch: 8 [140000/145035 (96%)]\tLoss: 1.603027\n","\n","Test set: Average loss: 0.5749\n","[[3174995   92429]\n"," [1063857   15757]]\n","\n","Threshold:0.2 Accuracy:73%\n","\n","[[3267424       0]\n"," [1079614       0]]\n","\n","Threshold:0.3 Accuracy:75%\n","\n","[[3267424       0]\n"," [1079614       0]]\n","\n","Threshold:0.4 Accuracy:75%\n","\n","[[3267424       0]\n"," [1079614       0]]\n","\n","Threshold:0.5 Accuracy:75%\n","\n","[[3267424       0]\n"," [1079614       0]]\n","\n","Threshold:0.5 Accuracy:75%\n","\n","[[3267424       0]\n"," [1079614       0]]\n","\n","Threshold:0.6 Accuracy:75%\n","\n","[[3267424       0]\n"," [1079614       0]]\n","\n","Threshold:0.7 Accuracy:75%\n","\n","9\n","Train Epoch: 9 [0/145035 (0%)]\tLoss: 1.547163\n","Train Epoch: 9 [20000/145035 (14%)]\tLoss: 1.709819\n","Train Epoch: 9 [40000/145035 (28%)]\tLoss: 1.681676\n","Train Epoch: 9 [60000/145035 (41%)]\tLoss: 1.632812\n","Train Epoch: 9 [80000/145035 (55%)]\tLoss: 1.632059\n","Train Epoch: 9 [100000/145035 (69%)]\tLoss: 1.655988\n","Train Epoch: 9 [120000/145035 (83%)]\tLoss: 1.659589\n","Train Epoch: 9 [140000/145035 (96%)]\tLoss: 1.618142\n","\n","Test set: Average loss: 0.5814\n","[[3274703     676]\n"," [1071659       0]]\n","\n","Threshold:0.2 Accuracy:75%\n","\n","[[3275379       0]\n"," [1071659       0]]\n","\n","Threshold:0.3 Accuracy:75%\n","\n","[[3275379       0]\n"," [1071659       0]]\n","\n","Threshold:0.4 Accuracy:75%\n","\n","[[3275379       0]\n"," [1071659       0]]\n","\n","Threshold:0.5 Accuracy:75%\n","\n","[[3275379       0]\n"," [1071659       0]]\n","\n","Threshold:0.5 Accuracy:75%\n","\n","[[3275379       0]\n"," [1071659       0]]\n","\n","Threshold:0.6 Accuracy:75%\n","\n","[[3275379       0]\n"," [1071659       0]]\n","\n","Threshold:0.7 Accuracy:75%\n","\n"]}],"source":["for i in range(epoch):\n","    print(i)\n","    train(model, device, trainLoader, optimizer, i)\n","    valid(model, device, validLoader, epoch)\n","# writer.export_scalars_to_json(\"./all_scalars.json\")\n","# writer.close()"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mC:\\Users\\ZHENXU~1\\AppData\\Local\\Temp/ipykernel_30672/3169362439.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvalid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidLoader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mC:\\Users\\ZHENXU~1\\AppData\\Local\\Temp/ipykernel_30672/1092762671.py\u001b[0m in \u001b[0;36mvalid\u001b[1;34m(model, device, validloader, epoch)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalidloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mE:\\Envs\\variant_transformer\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\Users\\ZHENXU~1\\AppData\\Local\\Temp/ipykernel_30672/1741268939.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpositionalEncoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mE:\\Envs\\variant_transformer\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\Users\\ZHENXU~1\\AppData\\Local\\Temp/ipykernel_30672/1812174225.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, src_mask)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mE:\\Envs\\variant_transformer\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\Users\\ZHENXU~1\\AppData\\Local\\Temp/ipykernel_30672/3570846359.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, src_mask)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# 1. compute self attention\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0m_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# 2. add and norm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mE:\\Envs\\variant_transformer\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\Users\\ZHENXU~1\\AppData\\Local\\Temp/ipykernel_30672/1957915770.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, q, k, v, mask)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# 3. do scale dot product to compute similarity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# 4. concat and pass to linear layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mE:\\Envs\\variant_transformer\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\Users\\ZHENXU~1\\AppData\\Local\\Temp/ipykernel_30672/148320013.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, q, k, v, mask, e)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m# 2. apply masking (opt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# 3. pass them softmax to make [0, 1] range\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["valid(model, device, validLoader, 1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# att_heads = [1, 3]\n","# hidden_dims = [128, 256, 512, 1024]\n","# layers = [2, 4, 6, 8, 10]\n","\n","# for head_num in att_heads:\n","#     for hidden_dim in hidden_dims:\n","#         for layer in layers:\n","#             print(head_num, hidden_dim, layer)\n","#             model = EnhancerClassifier(\n","#                 embedding_num = embedding_num,\n","#                 embedding_dim=embedding_dim,\n","#                 pad_idx=pad_idx,\n","#                 pad_size=pad_size,\n","#                 device=device,\n","#                 output_dim=label_dim,\n","#                 att_head_num=head_num,\n","#                 hidden_dim=hidden_dim,\n","#                 n_layers =layer\n","#             )\n","#             # %%\n","#             for i in range(epoch):\n","#                 print(\"-----epoch {}-----\".format(i))\n","#                 train(model, device, trainLoader, optimizer, i)\n","#                 valid(model, device, validLoader)\n","        \n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tensorboardX import SummaryWriter"]}],"metadata":{"interpreter":{"hash":"796fac6b8cc66e26d7d5167379612d61b69e4c93c285e3908b5ef16019a4c00d"},"kernelspec":{"display_name":"Python 3.7.9 64-bit ('variant_transformer': virtualenv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
